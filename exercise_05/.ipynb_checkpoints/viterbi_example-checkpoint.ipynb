{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi example\n",
    "The goal is to illustrate with a simple example how the Viterbi algorithm works\n",
    "\n",
    "You should try to show how the Viterbi algorithm will tag the sequence.\n",
    "\n",
    "*A green object shows up.*\n",
    "\n",
    "We are using the unsmoothed counts from Brown for the tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is hopefully self-explaining given the variable names and our earlier exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sents = brown.tagged_sents( tagset='universal')\n",
    "tagged_words = [(w.lower(),t) for s in tagged_sents for (w,t) in s]\n",
    "words = [w for (w,t) in tagged_words]\n",
    "padded_tag_sequences = [['<s>']+[t for w,t in s]+['<\\s>'] for s in tagged_sents]\n",
    "tags = [t[i] for t in padded_tag_sequences for i in range(len(t))]\n",
    "tag_bigrams = [(t[i], t[i+1]) for t in padded_tag_sequences for i in range(len(t)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freqs = nltk.FreqDist(words)\n",
    "tag_freqs = nltk.FreqDist(tags)\n",
    "word_tag_freqs = nltk.ConditionalFreqDist(tagged_words)\n",
    "tag_word_freqs = nltk.ConditionalFreqDist((t, w) for (w,t) in tagged_words)\n",
    "tag_tag_freqs = nltk.ConditionalFreqDist(tag_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can read off the bigram counts and the unigram counts for the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         .  <\\s>   ADJ   ADP   ADV  CONJ   DET  NOUN   NUM  PRON   PRT  VERB     X \n",
      "   . 15811 56149  4261  9625  6429 10239 10003 12226  1780  6838  2705 11313   186 \n",
      " <s>  5099     0  1969  7044  5238  2817 12238  8093   964  9157  2103  2588    30 \n",
      " ADJ  8404    31  4765  7407   810  3147   489 54645   584   320  1614  1463    42 \n",
      " ADP  1411     8 11961  2939  2244   273 65960 37415  4357 10102  2062  5967    67 \n",
      " ADV  9570    20  7666  7979  5446   974  4136  1846   747  2719  1613 13518     5 \n",
      "CONJ   794     2  4272  2796  3484    10  5772  9294   713  2579   959  7455    21 \n",
      " DET  1751    18 32846  1243  2400    88   809 85838  1338  1358   275  8861   194 \n",
      "NOUN 78181   914  3553 67325  7272 16447  4270 41144  2222  5460  4915 43763    92 \n",
      " NUM  4027    80   882  1950   303   570   195  5659   323   126    79   677     3 \n",
      "PRON  5116     5   468  2753  2665   562   864   437    49   404  1172 34838     1 \n",
      " PRT  2288     9   564  2706  1079   364  2492  1066   152   204   335 18568     2 \n",
      "VERB 14733   102 10510 30925 18859  2628 29784 17819  1644 10058 11987 33667    34 \n",
      "   X   380     2     4    74    10    32     7    76     1     9    10    72   709 \n"
     ]
    }
   ],
   "source": [
    "tag_tag_freqs.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NOUN   VERB      .    ADP    DET    ADJ    <s>   <\\s>    ADV   PRON   CONJ    PRT    NUM      X \n",
      "275558 182750 147565 144766 137019  83721  57340  57340  56239  49334  38151  29829  14874   1386 \n"
     ]
    }
   ],
   "source": [
    "tag_freqs.tabulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this is should be possible to estimate the conditional bigram probabilities P(t2 | t1). You don't have to do that for all pairs, only for the ones that pop up during the tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each word we only consider the tags with which the word actually occurs in the corpus. The following calculations yield\n",
    "\n",
    "- the total frequency for each word\n",
    "- the total frequency for each pair of word and tag\n",
    "- the total frequency for each tag\n",
    "\n",
    "(Some information is repeated, e.g. Count(NOUN). That's only because it was a simpe way to write it. Don't let it distract you.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count(a)=23195\n",
      "Count(a, DET)=23070\tCount(DET)=137019\n",
      "Count(a, NOUN)=116\tCount(NOUN)=275558\n",
      "Count(a, X)=9\tCount(X)=1386\n",
      "\n",
      "Count(green)=116\n",
      "Count(green, ADJ)=85\tCount(ADJ)=83721\n",
      "Count(green, NOUN)=31\tCount(NOUN)=275558\n",
      "\n",
      "Count(object)=65\n",
      "Count(object, NOUN)=53\tCount(NOUN)=275558\n",
      "Count(object, VERB)=12\tCount(VERB)=182750\n",
      "\n",
      "Count(shows)=94\n",
      "Count(shows, NOUN)=21\tCount(NOUN)=275558\n",
      "Count(shows, VERB)=73\tCount(VERB)=182750\n",
      "\n",
      "Count(up)=1890\n",
      "Count(up, PRT)=1711\tCount(PRT)=29829\n",
      "Count(up, ADP)=179\tCount(ADP)=144766\n",
      "\n",
      "Count(.)=49346\n",
      "Count(., .)=49346\tCount(.)=147565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w in ['a', 'green', 'object', 'shows', 'up', '.']:\n",
    "    print(\"Count({})={}\". format(w, word_freqs[w]))\n",
    "    for t in word_tag_freqs[w]:\n",
    "        print(\"Count({}, {})={}\\tCount({})={}\".format(w, t, word_tag_freqs[w][t], t, tag_freqs[t]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have  all the information you need for describing how the Viterbi algorithm will parse the sentence with a bigram HMM. Please do that.\n",
    "\n",
    "*A green object shows up.*\n",
    "\n",
    "Don't apply smoothing. You may discard the 9 occurrences of 'a' as X or NOUN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
